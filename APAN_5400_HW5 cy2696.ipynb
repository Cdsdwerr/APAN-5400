{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a62c0bdb",
      "metadata": {
        "id": "a62c0bdb"
      },
      "source": [
        "# Assignment 5 Cheng Ye cy2696"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01ffad82",
      "metadata": {
        "id": "01ffad82"
      },
      "source": [
        "### Install PySpark (Python Spark API)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9445184d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9445184d",
        "outputId": "ac2bd9cb-495d-48f8-ed2d-0b07e145dd81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285397 sha256=7a49d288f0de3bee23d15bd151c536710818c7edeb930479ffd4ebc1fa38bbc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b768f108",
      "metadata": {
        "id": "b768f108"
      },
      "source": [
        "### Loading Initial Libraries for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b9436f6",
      "metadata": {
        "id": "4b9436f6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8d9e75",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f8d9e75",
        "outputId": "d4a30891-7689-48a1-ec83-9d200168c266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Apache Spark Version 3.4.1\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SQLContext\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "print(\"Using Apache Spark Version\", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cfcab1c",
      "metadata": {
        "id": "2cfcab1c"
      },
      "source": [
        "### Read a large CSV file into a Spark dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb64039",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bb64039",
        "outputId": "d1ce6b39-9a75-4a58-ccd6-6059e2db69bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1127735"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "cb_sdf = spark.read.format(\"csv\") \\\n",
        "               .options(header='true', inferschema='true', treatEmptyValuesAsNulls='true') \\\n",
        "               .load(\"/content/crunchbase_odm_orgs.csv\")\n",
        "cb_sdf.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "685d04eb",
      "metadata": {
        "id": "685d04eb"
      },
      "source": [
        "## Implement PySpark code using DataFrames, RDDs or Spark UDF functions to answer questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31501a4",
      "metadata": {
        "id": "f31501a4"
      },
      "source": [
        " ### Question1 : Find all companies with the name that is only two words (e.g. : \"Goldman Sachs\")\n",
        " print the count of such companies and show()only the name and location (city, region, country_code) in the resulting Spark DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e7f8f5e",
      "metadata": {
        "id": "2e7f8f5e"
      },
      "outputs": [],
      "source": [
        "cb_rdd = cb_sdf.select('*').rdd.map(lambda row: [str(row[i]) for i in ['name','city','region','country_code']])\n",
        "\n",
        "cb_sdf2 = spark.createDataFrame(cb_rdd,['name','city','region','country_code'])\n",
        "import pyspark.sql.functions as F\n",
        "companies_2 = cb_sdf2.where(F.size(F.split(F.col(\"name\"), \" \")) == 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddcddb67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddcddb67",
        "outputId": "1acab51e-79bd-48eb-aa7c-31da5febe193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of companies with names that are only two words:  362534\n"
          ]
        }
      ],
      "source": [
        "print(\"Count of companies with names that are only two words: \",companies_2.count()) # showing all companies with the name that is only two words (e.g. : \"Goldman Sachs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc50832f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc50832f",
        "outputId": "31522801-c8f9-4e4d-8f01-85bdbc4acb6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------------+----------+------------+\n",
            "|                name|            city|    region|country_code|\n",
            "+--------------------+----------------+----------+------------+\n",
            "|         Time Warner|        New York|  New York|         USA|\n",
            "|       Goldman Sachs|        New York|  New York|         USA|\n",
            "|     Jingle Networks|        New York|  New York|         USA|\n",
            "|Hearst Communicat...|        New York|  New York|         USA|\n",
            "|    Ning Interactive|      Menlo Park|California|         USA|\n",
            "| Prosper Marketplace|   San Francisco|California|         USA|\n",
            "|       Tribune Media|         Chicago|  Illinois|         USA|\n",
            "| Aggregate Knowledge|       San Mateo|California|         USA|\n",
            "|        Zing Systems|   Mountain View|California|         USA|\n",
            "|         Amie Street|Long Island City|  New York|         USA|\n",
            "|          Legg Mason|       Baltimore|  Maryland|         USA|\n",
            "|        Haute Secure|         Seattle|Washington|         USA|\n",
            "|          Squid Labs|         Alameda|California|         USA|\n",
            "|           SAY Media|   San Francisco|California|         USA|\n",
            "|Metaweb Technologies|   San Francisco|California|         USA|\n",
            "|          Mode Media|        Brisbane|California|         USA|\n",
            "|          Linden Lab|   San Francisco|California|         USA|\n",
            "| Broadband Mechanics|    Walnut Creek|California|         USA|\n",
            "|       TheFind, Inc.|   Mountain View|California|         USA|\n",
            "|          Cafe Press|      Louisville|  Colorado|         USA|\n",
            "+--------------------+----------------+----------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "companies_2.show() # showing only the name and location (city, region, country_code) in the resulting Spark DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbcb245c",
      "metadata": {
        "id": "fbcb245c"
      },
      "source": [
        "### Question2 : Find all companies located in the state of California:\n",
        "print the count of such companies and show()only the name and location (city, region, country_code) in the resulting Spark DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f29e6721",
      "metadata": {
        "id": "f29e6721"
      },
      "outputs": [],
      "source": [
        "import pyspark.sql.functions as F\n",
        "companies_ca = cb_sdf2.where(F.col('region') == \"California\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dbc3aa3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dbc3aa3",
        "outputId": "a997f768-7694-4d3a-9ca3-8f9c84f6ecbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of companies with names that are located in the state of California:  94871\n"
          ]
        }
      ],
      "source": [
        "print(\"Count of companies with names that are located in the state of California: \",companies_ca.count()) # showing all companies located in the state of California"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8665c46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8665c46",
        "outputId": "2aa4ae3f-a62e-4bc1-d387-c39ef11749ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+----------+------------+\n",
            "|                name|          city|    region|country_code|\n",
            "+--------------------+--------------+----------+------------+\n",
            "|                Zoho|    Pleasanton|California|         USA|\n",
            "|            Facebook|    Menlo Park|California|         USA|\n",
            "|               Accel|     Palo Alto|California|         USA|\n",
            "|           Omnidrive|     Palo Alto|California|         USA|\n",
            "|                Geni|West Hollywood|California|         USA|\n",
            "|             Flektor|   Culver City|California|         USA|\n",
            "|Fox Interactive M...| Beverly Hills|California|         USA|\n",
            "|             Twitter| San Francisco|California|         USA|\n",
            "|         StumbleUpon| San Francisco|California|         USA|\n",
            "|              Scribd| San Francisco|California|         USA|\n",
            "|             Slacker|     San Diego|California|         USA|\n",
            "|                Lala|     Palo Alto|California|         USA|\n",
            "|               Helio|   Los Angeles|California|         USA|\n",
            "|                eBay|      San Jose|California|         USA|\n",
            "|             Postini|    San Carlos|California|         USA|\n",
            "|               Plaxo|     Sunnyvale|California|         USA|\n",
            "|               Cisco|      San Jose|California|         USA|\n",
            "|            Powerset| San Francisco|California|         USA|\n",
            "|          Technorati| San Francisco|California|         USA|\n",
            "|               OpenX|      Pasadena|California|         USA|\n",
            "+--------------------+--------------+----------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "companies_ca.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8fc3021",
      "metadata": {
        "id": "b8fc3021"
      },
      "source": [
        "### Question3 : Add a \"Blog\" column to the DataFrame with the row entries set to 1 if the \"domain\" field contains \"blogspot.com\", and 0 otherwise.\n",
        "show() only the name, location (city, region, country_code) and \"Blog\" column for companies with the \"Blog\" field marked as 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2aa359b",
      "metadata": {
        "id": "a2aa359b"
      },
      "outputs": [],
      "source": [
        "cb_rdd = cb_sdf.select('*').rdd.map(lambda row: [str(row[i]) for i in ['name','domain','city','region','country_code']])\n",
        "\n",
        "cb_sdf3 = spark.createDataFrame(cb_rdd,['name','domain','city','region','country_code'])\n",
        "\n",
        "blog_add = cb_sdf3.select(\"*\").withColumn(\"Blog\", F.when(F.col(\"domain\").contains(\"blogspot.com\"), 1).otherwise(0))\n",
        "\n",
        "companies_blog = blog_add.select('name','city','region','country_code','Blog')\n",
        "\n",
        "comapnies_blog = companies_blog.where(F.col('Blog') == 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "852ef5f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "852ef5f5",
        "outputId": "609f99e4-df76-41e1-e053-621ec1181e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of companies with 'domain' field contains blogspot.com:  394\n"
          ]
        }
      ],
      "source": [
        "print(\"Count of companies with 'domain' field contains blogspot.com: \",comapnies_blog.count()) # showing all companies with blogspot.com in their domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d651101",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d651101",
        "outputId": "2c139c30-80c5-45db-ff28-9927e0d0f043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+------------+------------+----+\n",
            "|                name|         city|      region|country_code|Blog|\n",
            "+--------------------+-------------+------------+------------+----+\n",
            "|     Sad Urdu Poetry|  San Antonio|       Texas|         USA|   1|\n",
            "|      The Tech-Freak|    Sheffield|   Sheffield|         GBR|   1|\n",
            "|           Ma.Gnolia|San Francisco|  California|         USA|   1|\n",
            "|      Dynasty Online|         None|        None|        None|   1|\n",
            "|            Hire-seo|         None|        None|        None|   1|\n",
            "|          YelloYello|     Rijswijk|Zuid-Holland|         NLD|   1|\n",
            "|       Youtubehiphop|    São Paulo|   Sao Paulo|         BRA|   1|\n",
            "|     Payday advances|         None|        None|        None|   1|\n",
            "|Blog Traffic Exch...|   Menlo Park|  California|         USA|   1|\n",
            "|Sirius Forex Trad...|         None|        None|        None|   1|\n",
            "|          Utilsforge|     Delaware|        Ohio|         USA|   1|\n",
            "|      Discover India|    Faridabad|     Haryana|         IND|   1|\n",
            "|   Latest Home Decor|         None|        None|        None|   1|\n",
            "|Sanguinet Consulting|San Francisco|  California|         USA|   1|\n",
            "|  john kenneth rosel|San Francisco|  California|         USA|   1|\n",
            "|Web Solution Prov...|         None|        None|        None|   1|\n",
            "|Walking Ants Tech...|         None|        None|        None|   1|\n",
            "|      BypassFanPages|         None|        None|        None|   1|\n",
            "|      List Australia|    Melbourne|    Victoria|         AUS|   1|\n",
            "|NeverAnEmptyGlass...|   Scottsdale|     Arizona|         USA|   1|\n",
            "+--------------------+-------------+------------+------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "comapnies_blog.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72bc1de",
      "metadata": {
        "id": "e72bc1de"
      },
      "source": [
        "### Question4 : Find all companies with names that are palindromes (name reads the same way forward and reverse, e.g. madam) using Spark UDF function:\n",
        "print the count and show() only the name and location (city, region, country_code) in the resulting Spark DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c325a514",
      "metadata": {
        "id": "c325a514"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import udf\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "def is_palindrome(s):\n",
        "    if s is None:\n",
        "        return False\n",
        "    return s.lower() == s[::-1].lower()\n",
        "\n",
        "spark_udf = udf(is_palindrome, StringType())\n",
        "\n",
        "cb_sdf4 = cb_sdf.withColumn('palindrome',spark_udf('name'))\n",
        "\n",
        "companies = cb_sdf4['name','palindrome','city','region','country_code']\n",
        "\n",
        "companies_pali = companies.filter(F.col('palindrome') == 'true')\n",
        "\n",
        "companies_pali = companies_pali['name','city','region','country_code']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a2d684e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a2d684e",
        "outputId": "35305c33-97ca-4b0b-8b1b-a4faf0fc974b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of companies with names that are palindromes:  1132\n"
          ]
        }
      ],
      "source": [
        "print(\"Count of companies with names that are palindromes: \", companies_pali.count()) #showing all companies with names that are palindromes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7019d44c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7019d44c",
        "outputId": "08839c42-ba02-49a2-be23-f5e65cafe806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+------------+\n",
            "|   name|                city|              region|country_code|\n",
            "+-------+--------------------+--------------------+------------+\n",
            "| Revver|         Los Angeles|          California|         USA|\n",
            "|  KAYAK|            Stamford|         Connecticut|         USA|\n",
            "|  ooVoo|            New York|            New York|         USA|\n",
            "|Imikimi|             Seattle|          Washington|         USA|\n",
            "|   Teet|        Lva Tolstogo|              Kaluga|         RUS|\n",
            "| Mollom|Berchem-sainte-ag...|Brussels Hoofdste...|         BEL|\n",
            "|  63336|              London|             England|         GBR|\n",
            "|  TipiT|               Delft|        Zuid-Holland|         NLD|\n",
            "|  beweb|            Auckland|            Auckland|         NZL|\n",
            "|    CSC|        Falls Church|            Virginia|         USA|\n",
            "|    CBC|              Ottawa|             Ontario|         CAN|\n",
            "|  Orbro|              Howell|            Michigan|         USA|\n",
            "|    OQO|       San Francisco|          California|         USA|\n",
            "|Revyver|                null|                null|        null|\n",
            "|    SAS|                Cary|      North Carolina|         USA|\n",
            "|WowOwow|            New York|            New York|         USA|\n",
            "|    e4e|         Santa Clara|          California|         USA|\n",
            "|    PHP|         Little Rock|            Arkansas|         USA|\n",
            "|    ivi|              Moscow|         Moscow City|         RUS|\n",
            "|   ADDA|           Bangalore|           Karnataka|         IND|\n",
            "+-------+--------------------+--------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "companies_pali.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}